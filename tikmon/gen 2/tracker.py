#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import subprocess
from datetime import datetime
from pathlib import Path
import re
from typing import List, Dict, Tuple
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from queue import Queue

class TikTokTracker:
    def __init__(self):
        self.users_file = "users.txt"
        self.data_file = "tiktok_data.json"
        self.thumbnails_dir = "thumbnails"
        self.html_file = "index.html"
        self.temp_data_file = "tiktok_data_temp.json"  # Ù…Ù„Ù Ù…Ø¤Ù‚Øª Ù„Ù„Ø­ÙØ¸ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ± Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        Path(self.thumbnails_dir).mkdir(exist_ok=True)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
        self.data = self.load_data()
        
        # Lock Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø¢Ù…Ù† Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¹Ø¯Ø© threads
        self.data_lock = threading.Lock()
        self.save_lock = threading.Lock()
        self.print_lock = threading.Lock()
        
        # Ø¹Ø¯Ø§Ø¯ Ù„Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        self.processed_videos_count = 0
        self.total_new_videos = 0

# START: MODIFIED SECTION
        # --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© (Circuit Breaker) ---
        self.consecutive_timeouts = 0
        self.timeout_lock = threading.Lock() # Lock Ù„Ø¶Ù…Ø§Ù† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹Ø¯Ø§Ø¯ Ø¨Ø£Ù…Ø§Ù†
        self.TIMEOUT_THRESHOLD = 10  # Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„ÙØ´Ù„ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ© Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø·Ø¹
        self.COOLDOWN_PERIOD = 60    # Ù…Ø¯Ø© Ø§Ù„ØªÙˆÙ‚Ù Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
# END: MODIFIED SECTION
    
    def safe_print(self, message: str):
        """Ø·Ø¨Ø§Ø¹Ø© Ø¢Ù…Ù†Ø© Ù…Ù† Ø¹Ø¯Ø© threads"""
        with self.print_lock:
            print(message)
    
    def load_data(self) -> Dict:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª Ø£ÙˆÙ„Ø§Ù‹ (ÙÙŠ Ø­Ø§Ù„Ø© ØªÙˆÙ‚Ù Ù…ÙØ§Ø¬Ø¦)
        if os.path.exists(self.temp_data_file):
            try:
                with open(self.temp_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.safe_print(f"âš ï¸ Found temporary data file. Recovering from previous session...")
                # Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª Ù„ÙŠØµØ¨Ø­ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
                os.rename(self.temp_data_file, self.data_file)
                return data
            except:
                pass
        
        if os.path.exists(self.data_file):
            try:
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except json.JSONDecodeError:
                self.safe_print(f"âš ï¸ Warning: Data file {self.data_file} is corrupted. Starting fresh.")
                return {"users": {}}
            except Exception as e:
                self.safe_print(f"âŒ Unexpected error while reading {self.data_file}: {e}")
                return {"users": {}}
        return {"users": {}}
    
    def save_data(self, is_temp=False):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù JSON"""
        with self.save_lock:
            filename = self.temp_data_file if is_temp else self.data_file
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(self.data, f, ensure_ascii=False, indent=2)
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØŒ Ø§Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                if not is_temp and os.path.exists(self.temp_data_file):
                    os.remove(self.temp_data_file)
            except Exception as e:
                self.safe_print(f"âŒ Error saving data to {filename}: {e}")
    
    def get_users(self) -> List[str]:
        """Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        if not os.path.exists(self.users_file):
            self.safe_print(f"âŒ File not found: {self.users_file}")
            return []
        
        with open(self.users_file, 'r', encoding='utf-8') as f:
            users = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        
        return users
    
    def extract_video_id(self, url: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        match = re.search(r'/video/(\d+)', url)
        if match:
            return match.group(1)
        return url.split('/')[-1]
    
# START: MODIFIED SECTION
    def download_thumbnail_single(self, video_url: str, username: str, video_num: int = 0) -> str:
        """ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆÙ‚Ø§Ø·Ø¹ Ø¯Ø§Ø¦Ø±Ø© Ø°ÙƒÙŠ."""
        MAX_RETRIES = 3
        BACKOFF_FACTOR = 2

        video_id = self.extract_video_id(video_url)
        base_filename = f"{username}_{video_id}"
        
        for ext in ['.jpg', '.jpeg', '.webp', '.png', '.image']:
            existing_path = os.path.join(self.thumbnails_dir, base_filename + ext)
            if os.path.exists(existing_path):
                self.safe_print(f"      âœ“ Thumbnail already exists for video {video_num}: {video_id}")
                return existing_path
        
        self.safe_print(f"      ğŸ“· Downloading thumbnail for video {video_num}: {video_id}")
        
        for attempt in range(MAX_RETRIES):
            try:
                output_template = os.path.join(self.thumbnails_dir, base_filename)
                cmd = ["yt-dlp", "--write-thumbnail", "--skip-download", "--convert-thumbnails", "jpg", "-o", output_template, "--quiet", video_url]
                subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', check=True, timeout=30)
                
                # --- Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­ØŒ Ø£Ø¹Ø¯ Ø¶Ø¨Ø· Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙØ´Ù„ ---
                with self.timeout_lock:
                    self.consecutive_timeouts = 0

                final_path = output_template + '.jpg'
                if os.path.exists(final_path):
                    return final_path
                for ext in ['.jpeg', '.webp', '.png', '.image']:
                    fallback_path = output_template + ext
                    if os.path.exists(fallback_path):
                        return fallback_path
                
                return None

            except subprocess.TimeoutExpired:
                if attempt < MAX_RETRIES - 1:
                    delay = BACKOFF_FACTOR ** attempt
                    self.safe_print(f"      âš ï¸ Timeout for video {video_num}. Retrying in {delay}s...")
                    time.sleep(delay)
                else:
                    self.safe_print(f"      âŒ Final Timeout for video {video_num}. Registering failure.")
                    # --- Ù‡Ù†Ø§ ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ù…Ù†Ø·Ù‚ Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© ---
                    with self.timeout_lock:
                        self.consecutive_timeouts += 1
                        if self.consecutive_timeouts >= self.TIMEOUT_THRESHOLD:
                            self.safe_print("\n" + "="*70)
                            self.safe_print(f"ğŸš¨ CIRCUIT BREAKER TRIPPED! Too many consecutive timeouts ({self.consecutive_timeouts}).")
                            self.safe_print("   - Simulating restart to reset connection state...")
                            
                            # Ø§Ù„Ø®Ø·ÙˆØ© 1: Ù…Ø­Ø§ÙƒØ§Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø­Ø°Ù cache Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ yt-dlp
                            self.safe_print(f"   - Clearing yt-dlp cache to start fresh sessions...")
                            subprocess.run(["yt-dlp", "--rm-cache-dir"], capture_output=True)

                            # Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ ÙØªØ±Ø© ØªØ¨Ø±ÙŠØ¯ Ø·ÙˆÙŠÙ„Ø©
                            self.safe_print(f"   - Entering {self.COOLDOWN_PERIOD}s cooldown period. All downloads paused.")
                            time.sleep(self.COOLDOWN_PERIOD)
                            
                            self.consecutive_timeouts = 0 # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„Ø¹Ø¯Ø§Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¨Ø±ÙŠØ¯
                            self.safe_print("   - Cooldown finished. Resuming operations.")
                            self.safe_print("="*70 + "\n")
                    return None
            except Exception as e:
                self.safe_print(f"      âŒ Failed to download thumbnail for video {video_num}: {video_id} - {str(e)[:50]}")
                return None
        return None
# END: MODIFIED SECTION
    
    def download_thumbnails_batch(self, videos_data: List[Tuple[str, str, int]], username: str):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ"""
        self.safe_print(f"\n    ğŸ“¸ Starting parallel download of {len(videos_data)} thumbnails (8 concurrent)...")
        
        results = []
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = {
                executor.submit(self.download_thumbnail_single, url, username, num): (url, num) 
                for url, _, num in videos_data
            }
            
            for future in as_completed(futures):
                url, num = futures[future]
                try:
                    thumbnail_path = future.result()
                    results.append((url, thumbnail_path))
                except Exception as e:
                    self.safe_print(f"      âŒ Error in thumbnail download thread: {e}")
                    results.append((url, None))
        
        return results
    
    def process_user(self, username: str, user_number: int, total_users: int):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ø­Ø¯ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø°ÙƒÙŠØ© ÙˆØªÙØ§Ø¹Ù„ÙŠØ©"""
        self.safe_print(f"\n{'='*60}")
        self.safe_print(f"ğŸ”„ Processing user [{user_number}/{total_users}]: @{username}")
        self.safe_print(f"{'='*60}")
        
        process_start_time = time.time()

        # ØªÙ‡ÙŠØ¦Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        with self.data_lock:
            if username not in self.data["users"]:
                self.data["users"][username] = {
                    "videos": {},
                    "last_update": None
                }
            user_data = self.data["users"][username]
            existing_ids = set(user_data.get("videos", {}).keys())
            existing_count = len(existing_ids)
        
        self.safe_print(f"ğŸ“Š Current videos in database: {existing_count}")
        
        new_links_to_process = []
        duplicate_count = 0
        video_counter = 0
        
        self.safe_print(f"ğŸ“¥ Starting to fetch videos for @{username}...")
        fetch_start_time = time.time()
        
        url = f"https://www.tiktok.com/@{username}"
        cmd = ["yt-dlp", "--simulate", "--print", "%(webpage_url)s", url]
        
        process = None
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, 
                                     text=True, encoding='utf-8')

            for line in process.stdout:
                link = line.strip()
                if not link:
                    continue

                video_counter += 1
                video_id = self.extract_video_id(link)
                
                if video_id in existing_ids:
                    duplicate_count += 1
                    self.safe_print(f"    - Checking video {video_counter}: ID {video_id} (DUPLICATE #{duplicate_count})")
                    
                    if duplicate_count >= 3:
                        self.safe_print(f"    âœ… Found 3 consecutive duplicates. Stopping fetch for @{username}")
                        break
                else:
                    duplicate_count = 0
                    self.safe_print(f"    - Checking video {video_counter}: ID {video_id} (NEW)")
                    new_links_to_process.append((link, video_id, video_counter))

            process.terminate()
            process.wait(timeout=5)
            
            fetch_elapsed = time.time() - fetch_start_time
            self.safe_print(f"ğŸ“Š Fetch completed in {fetch_elapsed:.2f} seconds")

        except Exception as e:
            self.safe_print(f"âŒ Error processing @{username}: {e}")
            if process:
                process.kill()
            return

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        if not new_links_to_process:
            self.safe_print(f"âœ… No new videos found for @{username}")
        else:
            self.safe_print(f"ğŸ†• Found {len(new_links_to_process)} new videos to process")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØµØºØ±Ø© Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
            thumbnail_results = self.download_thumbnails_batch(new_links_to_process, username)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            with self.data_lock:
                save_counter = 0
                for (link, thumbnail_path), (_, video_id, _) in zip(thumbnail_results, new_links_to_process):
                    user_data["videos"][video_id] = {
                        "url": link,
                        "thumbnail": thumbnail_path,
                        "added_date": datetime.now().isoformat(),
                        "is_new": True
                    }
                    save_counter += 1
                    
                    # Ø­ÙØ¸ ØªØ¯Ø±ÙŠØ¬ÙŠ ÙƒÙ„ 50 ÙÙŠØ¯ÙŠÙˆ
                    if save_counter % 50 == 0:
                        self.safe_print(f"    ğŸ’¾ Auto-saving progress ({save_counter} videos processed)...")
                        self.save_data(is_temp=True)
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                newly_added_ids = {video_id for _, video_id, _ in new_links_to_process}
                for video_id, video_data in user_data["videos"].items():
                    if video_id not in newly_added_ids:
                        video_data["is_new"] = False
                
                user_data["last_update"] = datetime.now().isoformat()
                
                # Ø­ÙØ¸ Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
                self.save_data(is_temp=True)
                self.total_new_videos += len(new_links_to_process)
        
        total_elapsed = time.time() - process_start_time
        self.safe_print(f"âœ… Completed @{username} in {total_elapsed:.2f} seconds")
        self.safe_print(f"ğŸ“Š Total videos for @{username}: {len(user_data['videos'])}")
    
    def process_users_parallel(self, users: List[str]):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ (3 ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª)"""
        total_users = len(users)
        self.safe_print(f"\nğŸš€ Starting parallel processing of {total_users} users (3 concurrent)...")
        
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(self.process_user, username, idx+1, total_users): username 
                for idx, username in enumerate(users)
            }
            
            completed_count = 0
            for future in as_completed(futures):
                username = futures[future]
                completed_count += 1
                try:
                    future.result()
                    self.safe_print(f"\nâœ… [{completed_count}/{total_users}] Completed processing @{username}")
                except Exception as e:
                    self.safe_print(f"\nâŒ [{completed_count}/{total_users}] Error processing @{username}: {e}")