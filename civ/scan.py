import os
import subprocess
import json
import shutil
import time
import re
from pathlib import Path

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ---
BASE_DIR = Path("C:/Users/Stark").resolve()

# Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
DOWNLOAD_FOLDER = BASE_DIR / "Downloads"
DIB_FOLDER = Path(r"C:\Users\Stark\Download\myhome\video_rating_app\NS\TikTok\ELO TIK\Dib")
EXTRA_SCAN_FOLDER = BASE_DIR / "Desktop/Extra_Scan"

# Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ§Ø´
SCRIPT_DIR = Path(__file__).parent
MAIN_CACHE_FILE = SCRIPT_DIR / "image_cache.json"
SUBFOLDER_CACHE_FILE = SCRIPT_DIR / "subfolder_cache.json"

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ---

def clean_comfy_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    if not isinstance(text, str): return ""
    text = text.strip()
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ÙŠØ· Ø¨Ø§Ù„Ù†Øµ ÙƒØ§Ù…Ù„Ø§Ù‹
    if text.startswith('"') and text.endswith('"'): text = text[1:-1]
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    while text.startswith(','): text = text[1:].strip()
    while text.endswith(','): text = text[:-1].strip()
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
    text = re.sub(r',\s*,', ',', text)
    text = re.sub(r'\s+', ' ', text) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    return text.strip()

# --- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ---

def extract_text_from_node(node, all_nodes, visited=None):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø¹Ù‚Ø¯Ø©ØŒ Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠ"""
    if visited is None:
        visited = set()
    
    if not isinstance(node, dict):
        return ""
    
    # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠ
    node_id = id(node)
    if node_id in visited:
        return ""
    visited.add(node_id)
    
    inputs = node.get('inputs', {})
    
    # 1. Ø¬Ø±Ø¨ text Ù…Ø¨Ø§Ø´Ø±
    if 'text' in inputs:
        if isinstance(inputs['text'], str):
            return clean_comfy_text(inputs['text'])
        elif isinstance(inputs['text'], list) and len(inputs['text']) > 0:
            ref_str = str(inputs['text'][0])
            # Ø¬Ø±Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ÙƒØ§Ù…Ù„ Ø£ÙˆÙ„Ø§Ù‹ (Ù…Ø«Ù„ "51:0")
            ref_node = all_nodes.get(ref_str)
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ØŒ Ø¬Ø±Ø¨ Ø¨Ø¯ÙˆÙ† :
            if not ref_node and ':' in ref_str:
                ref_node = all_nodes.get(ref_str.split(':')[0])
            
            if ref_node:
                return extract_text_from_node(ref_node, all_nodes, visited)
    
    # 2. Ø¬Ø±Ø¨ widgets_values
    if isinstance(node.get('widgets_values'), list) and len(node['widgets_values']) > 0:
        widget_text = node['widgets_values'][0]
        if isinstance(widget_text, str) and widget_text:
            return clean_comfy_text(widget_text)
    
    return ""

def parse_comfyui_metadata(exif_data):
    """
    ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ComfyUI Ø¨Ù†Ù‡Ø¬ Ø°ÙƒÙŠ ÙŠØªØ¨Ø¹ KSampler
    
    Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª v3.0:
    - ÙŠØªØ¨Ø¹ Ø³Ù„Ø³Ù„Ø© positive/negative Ù…Ù† KSampler Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ØµØ­ÙŠØ­
    - Ø¯Ø¹Ù… JSON Ù…Ø¨Ø§Ø´Ø± ÙˆØ¨Ø§Ø¯Ø¦Ø© "Prompt:"
    - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹ (node_id Ùˆ node_id:output_index)
    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØ§Ù…Ù„ Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„
    """
    pos_prompt = ""
    neg_prompt = ""
    model_name = "ComfyUI_Model"
    settings = {}
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON
    raw_json = None
    if 'Make' in exif_data:
        make_content = str(exif_data['Make'])
        if make_content.startswith('Prompt:'):
            raw_json = make_content[7:]
        elif make_content.startswith('{'):
            raw_json = make_content
    
    if not raw_json and 'UserComment' in exif_data:
        raw_json = exif_data['UserComment']

    if not raw_json:
        return "", model_name

    try:
        data = json.loads(raw_json)
        
        # ØªØ­ÙˆÙŠÙ„ nodes Ø¥Ù„Ù‰ dict Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        nodes = {}
        if isinstance(data, dict):
            if 'nodes' in data and isinstance(data['nodes'], list):
                for n in data['nodes']:
                    nodes[str(n.get('id', ''))] = n
            else:
                nodes = data
        
        # ============== Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ø°ÙƒÙŠ: ØªØªØ¨Ø¹ Ù…Ù† KSampler ==============
        ksampler_found = False
        
        # 1. Ø§Ø¨Ø­Ø« Ø¹Ù† KSampler
        for node_id, node_data in nodes.items():
            if not isinstance(node_data, dict):
                continue
                
            class_type = str(node_data.get('class_type', '')).lower()
            if 'ksampler' in class_type:
                ksampler_found = True
                inputs = node_data.get('inputs', {})
                
                # Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
                if 'seed' in inputs and isinstance(inputs['seed'], (int, float)):
                    settings['Seed'] = int(inputs['seed'])
                if 'steps' in inputs and isinstance(inputs['steps'], (int, float)):
                    settings['Steps'] = int(inputs['steps'])
                if 'cfg' in inputs and isinstance(inputs['cfg'], (int, float)):
                    settings['CFG scale'] = float(inputs['cfg'])
                if 'sampler_name' in inputs and isinstance(inputs['sampler_name'], str):
                    settings['Sampler'] = inputs['sampler_name']
                if 'scheduler' in inputs and isinstance(inputs['scheduler'], str):
                    settings['Scheduler'] = inputs['scheduler']
                if 'denoise' in inputs and isinstance(inputs['denoise'], (int, float)):
                    settings['Denoising strength'] = float(inputs['denoise'])
                
                # ØªØªØ¨Ø¹ positive
                if 'positive' in inputs and isinstance(inputs['positive'], list) and len(inputs['positive']) > 0:
                    pos_node_id = str(inputs['positive'][0])
                    pos_node = nodes.get(pos_node_id)
                    if pos_node:
                        pos_prompt = extract_text_from_node(pos_node, nodes)
                
                # ØªØªØ¨Ø¹ negative
                if 'negative' in inputs and isinstance(inputs['negative'], list) and len(inputs['negative']) > 0:
                    neg_node_id = str(inputs['negative'][0])
                    neg_node = nodes.get(neg_node_id)
                    if neg_node:
                        neg_prompt = extract_text_from_node(neg_node, nodes)
                
                break  # ÙˆØ¬Ø¯Ù†Ø§ KSamplerØŒ Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„Ø¨Ø­Ø« Ø£ÙƒØ«Ø±
        
        # ============== Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ KSampler ==============
        if not ksampler_found:
            print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ KSamplerØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ")
            pos_candidates = []
            neg_candidates = []
            negative_keywords = [
                'lowres', 'worst quality', 'bad quality', 'bad anatomy', 'nsfw', 
                'watermark', 'jpeg artifacts', 'error', 'username', 'signature', 
                'censored', 'bar_censor', 'pregnant', 'chibi', 'loli', 
                'simple background', 'conjoined', 'futanari', 'sketch', 'old', 'oldest'
            ]
            
            for node_id, node_data in nodes.items():
                if not isinstance(node_data, dict):
                    continue
                
                text = extract_text_from_node(node_data, nodes)
                if text and len(text) > 2 and "[filename]" not in text and "TextBatch" not in text:
                    # ØªØµÙ†ÙŠÙ
                    neg_count = sum(1 for kw in negative_keywords if kw in text.lower())
                    starts_with_negative = any(text.lower().startswith(kw) for kw in ['lowres', 'worst quality', 'bad quality'])
                    
                    if neg_count >= 3 or starts_with_negative:
                        neg_candidates.append(text)
                    else:
                        pos_candidates.append(text)
            
            # Ø§Ø®ØªØ± Ø§Ù„Ø£ÙØ¶Ù„
            if pos_candidates:
                unique_pos = list(set(pos_candidates))
                # Ø£ÙØ¶Ù„ Ù†Øµ = Ø§Ù„Ø£Ø·ÙˆÙ„ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„
                pos_prompt = max(unique_pos, key=lambda x: len(x.replace(',', '').replace(' ', '')))
            
            if neg_candidates:
                unique_neg = list(set(neg_candidates))
                neg_prompt = ", ".join(unique_neg)
        
        # ============== Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ==============
        for node_id, node_data in nodes.items():
            if not isinstance(node_data, dict):
                continue
            
            class_type = str(node_data.get('class_type', '')).lower()
            inputs = node_data.get('inputs', {})
            
            # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
            if 'checkpoint' in class_type and 'ckpt_name' in inputs:
                model_name = inputs['ckpt_name']
            
            # Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            if 'latent' in class_type and 'width' in inputs and 'height' in inputs:
                if isinstance(inputs['width'], (int, float)) and isinstance(inputs['height'], (int, float)):
                    settings['Size'] = f"{int(inputs['width'])}x{int(inputs['height'])}"
        
    except (json.JSONDecodeError, AttributeError, KeyError) as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ComfyUI: {e}")
        return "", "ComfyUI_Model"
    
    # ============== ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ==============
    parts = []
    
    if pos_prompt:
        parts.append(pos_prompt)
    
    if neg_prompt:
        parts.append(f"Negative prompt: {neg_prompt}")
    
    if settings:
        settings_list = []
        order = ['Steps', 'CFG scale', 'Sampler', 'Scheduler', 'Seed', 'Size', 'Denoising strength']
        for key in order:
            if key in settings:
                settings_list.append(f"{key}: {settings[key]}")
        
        for k, v in settings.items():
            if k not in order:
                settings_list.append(f"{k}: {v}")
        
        if model_name != "ComfyUI_Model":
            settings_list.append(f"Model: {model_name}")
        
        if parts:
            parts.append("")
        parts.append(", ".join(settings_list))
    
    return "\n".join(parts), model_name


# --- Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ù‡Ùˆ ---

def extract_image_info(exif_data):
    model_name = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    prompt_data = ""

    # 1. ComfyUI Logic
    is_comfy = False
    if 'Make' in exif_data:
        make_content = str(exif_data['Make'])
        if make_content.startswith('Prompt:') or make_content.startswith('{'):
            is_comfy = True
    elif 'ImageDescription' in exif_data and str(exif_data['ImageDescription']).startswith('Workflow:'):
        is_comfy = True
        
    if is_comfy:
        p_text, m_name = parse_comfyui_metadata(exif_data)
        if p_text: prompt_data = p_text
        if m_name: model_name = m_name
        
    # 2. A1111 Logic
    elif 'UserComment' in exif_data or 'Parameters' in exif_data:
        text = exif_data.get('UserComment', '') or exif_data.get('Parameters', '')
        prompt_data = text
        match = re.search(r'Model: ([^,]+)', text)
        if match: model_name = match.group(1)

    return model_name, prompt_data


def find_images_with_exiftool(folder_path, extensions, check_ai_tag=False):
    print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ: {folder_path}")
    command = ['exiftool', '-json']
    command.extend(['-Make', '-ImageDescription', '-UserComment', '-Parameters', '-SourceFile', '-Directory', '-FileName', '-FileModifyDate'])
    
    for ext in extensions:
        clean_ext = ext.replace('.', '')
        command.extend(['-ext', clean_ext])
    
    command.append(str(folder_path))
    
    try:
        result = subprocess.run(
            command, capture_output=True, text=True, check=False, encoding='utf-8', errors='replace'
        )
        if not result.stdout: return []
        data = json.loads(result.stdout)
        return data if isinstance(data, list) else [data]
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        return []

def process_image_list(image_data_list, source_group_name="Main"):
    images_to_process = []
    for item in image_data_list:
        file_path = Path(item.get('SourceFile'))
        model_name, prompt_data = extract_image_info(item)
        source = item.get('_source_group', source_group_name)
        
        try:
            if file_path.is_relative_to(BASE_DIR):
                relative_path = file_path.relative_to(BASE_DIR)
                images_to_process.append({
                    'name': file_path.name,
                    'relative_path': str(relative_path).replace('\\', '/'),
                    'mod_time': item.get('FileModifyDate', ''),
                    'model_name': model_name,
                    'prompt_data': prompt_data,
                    'source_group': source
                })
        except: continue
    
    images_to_process.reverse() 
    return images_to_process

def scan_and_cache_images():
    start_time = time.time()
    print("--- Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙØ­Øµ Ø§Ù„Ø°ÙƒÙŠ (ComfyUI v3.0 + A1111) ---")

    if not shutil.which("exiftool"):
        print("\nâŒ Ø®Ø·Ø£: exiftool ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØªÙ‡ Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù….")
        return

    main_ai_images_raw = []
    supported_extensions = ['.png', '.jpg', '.jpeg', '.webp']

    # 1. Download
    if DOWNLOAD_FOLDER.is_dir():
        print(f"ğŸ“ ÙØ­Øµ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„...")
        images = find_images_with_exiftool(DOWNLOAD_FOLDER, supported_extensions)
        ai_images = []
        for img in images:
            if 'Make' in img or 'ImageDescription' in img or 'UserComment' in img or 'Parameters' in img:
                 img['_source_group'] = 'Download'
                 ai_images.append(img)
        main_ai_images_raw.extend(ai_images)

    # 2. Dib
    if DIB_FOLDER.is_dir():
        print(f"ğŸ“ ÙØ­Øµ Ù…Ø¬Ù„Ø¯ Dib...")
        images = find_images_with_exiftool(DIB_FOLDER, supported_extensions)
        for img in images: img['_source_group'] = 'Dib'
        main_ai_images_raw.extend(images)

    # 3. Extra
    if EXTRA_SCAN_FOLDER.is_dir():
        print(f"ğŸ“ ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ...")
        images = find_images_with_exiftool(EXTRA_SCAN_FOLDER, supported_extensions)
        for img in images: img['_source_group'] = 'Extra'
        main_ai_images_raw.extend(images)

    if main_ai_images_raw:
        final_list_processed = process_image_list(main_ai_images_raw)
        
        with open(MAIN_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(final_list_processed, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(final_list_processed)} ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ.")
    else:
        with open(MAIN_CACHE_FILE, 'w', encoding='utf-8') as f: json.dump([], f)
        print("ğŸŸ¡ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ±.")

    with open(SUBFOLDER_CACHE_FILE, 'w', encoding='utf-8') as f: json.dump({}, f)
    
    print(f"\n--- âœ… ØªÙ… Ø§Ù„ÙØ­Øµ ÙÙŠ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ© ---")

if __name__ == '__main__':
    scan_and_cache_images()