import os
import requests
from flask import Flask, request, jsonify
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import hashlib
import re
import glob
import time
from io import BytesIO  # Ù„Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©


# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
DOWNLOAD_FOLDER = r"C:\Users\Stark\Downloads\Civitai_Images"
PROCESSED_LINKS_DB = "processed_links.txt"
MIN_FILE_SIZE = 50 * 1024  # 50 ÙƒÙŠÙ„ÙˆØ¨Ø§ÙŠØª Ø¨Ø§Ù„Ø¨Ø§ÙŠØª


ORCHESTRATOR_TRACKING_FILES = [
    os.path.join(DOWNLOAD_FOLDER, "processed_anime4k.txt"),
    os.path.join(DOWNLOAD_FOLDER, "processed_esrgan.txt")
]

app = Flask(__name__)


# --- 2. ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ---

def setup():
    try:
        if not os.path.exists(DOWNLOAD_FOLDER):
            os.makedirs(DOWNLOAD_FOLDER)
            print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª: {DOWNLOAD_FOLDER}")
        if not os.path.exists(PROCESSED_LINKS_DB):
            with open(PROCESSED_LINKS_DB, "w") as f: pass
            print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {PROCESSED_LINKS_DB}")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯: {e}")
        exit()


def is_link_processed(url):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£ØµÙ„ÙŠ (Ø¨Ø¯ÙˆÙ† sig parameter)
    """
    url_without_sig = remove_signature_from_url(url)
    
    with open(PROCESSED_LINKS_DB, "r", encoding='utf-8') as f:
        for line in f:
            stored_url = line.strip()
            stored_url_without_sig = remove_signature_from_url(stored_url)
            if url_without_sig == stored_url_without_sig:
                return True
    return False


def add_link_to_db(url):
    with open(PROCESSED_LINKS_DB, "a", encoding='utf-8') as f:
        f.write(url + "\n")


def remove_signature_from_url(url):
    """
    Ø¥Ø²Ø§Ù„Ø© sig parameter Ù…Ù† URL Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
    """
    try:
        parsed = urlparse(url)
        query_params = parse_qs(parsed.query)
        query_params.pop('sig', None)
        new_query = urlencode(query_params, doseq=True)
        new_url = urlunparse((
            parsed.scheme,
            parsed.netloc,
            parsed.path,
            parsed.params,
            new_query,
            parsed.fragment
        ))
        return new_url
    except:
        return url


def is_already_processed_by_orchestrator(base_filename):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ ÙÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØªØ¨Ø¹
    """
    for tracker_file in ORCHESTRATOR_TRACKING_FILES:
        try:
            if not os.path.exists(tracker_file):
                continue
            
            with open(tracker_file, 'r', encoding='utf-8') as f:
                processed_files = f.read().splitlines()
                for processed_file in processed_files:
                    if processed_file.startswith(base_filename):
                        return True
        except Exception as e:
            print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ØªØªØ¨Ø¹ '{tracker_file}'. Ø§Ù„Ø®Ø·Ø£: {e}")
            continue
            
    return False


def file_exists_with_base_name(base_filename, folder):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Ù…Ø¹ Ø£ÙŠ Ù„Ø§Ø­Ù‚Ø©)
    """
    try:
        pattern = os.path.join(folder, f"{base_filename}_*")
        matching_files = glob.glob(pattern)
        
        if matching_files:
            print(f"   ğŸ” ÙˆØ¬Ø¯Ù†Ø§ Ù…Ù„Ù Ù…Ø·Ø§Ø¨Ù‚: {os.path.basename(matching_files[0])}")
            return True, matching_files[0]
        return False, None
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª: {e}")
        return False, None


def sanitize_filename(filename):
    return re.sub(r'[\\/*?:"<>|]', "", filename)


def generate_filename(url):
    """
    ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
    """
    try:
        parsed_url = urlparse(url)
        base_name_part = parsed_url.path.split('/')[-1]
        name, ext = os.path.splitext(base_name_part)
        safe_name = sanitize_filename(name)
        return safe_name, ext
    except Exception:
        url_without_sig = remove_signature_from_url(url)
        hash_name = hashlib.md5(url_without_sig.encode()).hexdigest()
        return hash_name, ".jpg"


# --- Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ---
def check_file_size_via_head(url, headers):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… HEAD request ÙÙ‚Ø·
    ÙŠØ±Ø¬Ø¹: (is_valid, file_size_bytes)
    """
    try:
        print(f"[ ğŸ“ ] Ø§Ù„Ø·Ø¨Ù‚Ø© 4: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¹Ø¨Ø± HEAD request...")
        head_response = requests.head(url, headers=headers, timeout=10, allow_redirects=True)
        
        content_length = head_response.headers.get('Content-Length')
        
        if content_length:
            file_size = int(content_length)
            file_size_kb = file_size / 1024
            print(f"   ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {file_size_kb:.2f} KB")
            
            if file_size < MIN_FILE_SIZE:
                print(f"   ğŸš« Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ (< 50 KB). Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠÙ‡ Ø¯ÙˆÙ† Ø­ÙØ¸ Ø§Ù„Ø±Ø§Ø¨Ø·.")
                return False, file_size
            else:
                print(f"   âœ… Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù‚Ø¨ÙˆÙ„ (>= 50 KB).")
                return True, file_size
        else:
            print(f"   âš ï¸ Ù„Ù… ÙŠØªÙˆÙØ± Content-Length ÙÙŠ HEAD response.")
            return None, None  # Ø³Ù†Ø­ØªØ§Ø¬ Ù„Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            
    except Exception as e:
        print(f"   âš ï¸ ÙØ´Ù„ HEAD request: {e}.")
        return None, None


def download_to_memory_and_check(url, headers):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (BytesIO) ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù…Ù‡ Ù‚Ø¨Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø©
    ÙŠØ±Ø¬Ø¹: (is_valid, bytes_data, file_size)
    """
    try:
        print(f"[ ğŸ’¾ ] ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…...")
        
        # Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… stream Ù„Ù„ÙƒÙØ§Ø¡Ø©
        response = requests.get(url, headers=headers, stream=True, timeout=30)
        response.raise_for_status()
        
        # Ø¥Ù†Ø´Ø§Ø¡ BytesIO ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        memory_file = BytesIO()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø´ÙƒÙ„ chunks
        for chunk in response.iter_content(chunk_size=8192):
            memory_file.write(chunk)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        file_size = memory_file.tell()
        file_size_kb = file_size / 1024
        print(f"   ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {file_size_kb:.2f} KB")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…
        if file_size < MIN_FILE_SIZE:
            print(f"   ğŸš« Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ (< 50 KB). Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡ Ø¯ÙˆÙ† Ø­ÙØ¸.")
            memory_file.close()
            return False, None, file_size
        else:
            print(f"   âœ… Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù‚Ø¨ÙˆÙ„. Ø¬Ø§Ù‡Ø² Ù„Ù„Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯.")
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§Ø­Ù‚Ø§Ù‹
            memory_file.seek(0)
            return True, memory_file.getvalue(), file_size
            
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
        raise


# --- 3. Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© (API Endpoint) ---

@app.route('/process-image', methods=['POST'])
def process_image_link():
    try:
        data = request.get_json()
        if not data or 'url' not in data:
            return jsonify({"status": "error", "message": "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ 'url' ÙÙŠ Ø§Ù„Ø·Ù„Ø¨."}), 400

        image_url = data['url']
        print(f"\n[ ğŸ“¥ ] ØªÙ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯: {image_url[:80]}...")

        # --- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ---
        if is_link_processed(image_url):
            print("[ ğŸŸ¡ ] Ø§Ù„Ø·Ø¨Ù‚Ø© 1: Ø§Ù„Ø±Ø§Ø¨Ø· Ù…ÙƒØ±Ø±. ØªÙ… Ø§Ù„ØªØ¬Ø§Ù‡Ù„.")
            return jsonify({"status": "skipped", "message": "Ø§Ù„Ø±Ø§Ø¨Ø· ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§."}), 200

        # --- ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ---
        base_filename, extension = None, None
        parsed_url = urlparse(image_url)

        if 'view' in parsed_url.path and 'filename=' in parsed_url.query:
            print("[ â„¹ï¸ ] ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø±Ø§Ø¨Ø· Ù…Ù† Ù†ÙˆØ¹ ComfyUI/Pinggy.")
            query_params = parse_qs(parsed_url.query)
            filename_from_query = query_params.get('filename', [None])[0]
            if filename_from_query:
                base_filename, extension = os.path.splitext(filename_from_query)
        
        if base_filename is None:
            print("[ â„¹ï¸ ] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£ØµÙ„ÙŠ (Civitai).")
            base_filename, extension = generate_filename(image_url)
        
        print(f"[ â„¹ï¸ ] Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ù„Ù: {base_filename}")

        # --- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… ---
        exists, existing_file = file_exists_with_base_name(base_filename, DOWNLOAD_FOLDER)
        if exists:
            print(f"[ ğŸŸ¡ ] Ø§Ù„Ø·Ø¨Ù‚Ø© 2: ÙˆØ¬Ø¯Ù†Ø§ Ù…Ù„Ù Ù…Ø·Ø§Ø¨Ù‚. ØªÙ… Ø§Ù„ØªØ¬Ø§Ù‡Ù„.")
            add_link_to_db(image_url)
            return jsonify({"status": "skipped", "message": f"Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯: {os.path.basename(existing_file)}"}), 200

        # --- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---
        if is_already_processed_by_orchestrator(base_filename):
            print(f"[ ğŸŸ¡ ] Ø§Ù„Ø·Ø¨Ù‚Ø© 3: Ø§Ù„Ù…Ù„Ù Ù…Ø¹Ø§Ù„Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹. ØªÙ… Ø§Ù„ØªØ¬Ø§Ù‡Ù„.")
            add_link_to_db(image_url)
            return jsonify({"status": "skipped", "message": f"Ø§Ù„Ù…Ù„Ù '{base_filename}' Ù…Ø¹Ø§Ù„Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹."}), 200

        # --- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ---
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 1: HEAD request Ø£ÙˆÙ„Ø§Ù‹
        is_size_valid, file_size = check_file_size_via_head(image_url, headers)
        
        if is_size_valid is False:
            # Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ - Ù†ØªØ®Ø·Ø§Ù‡ Ø¯ÙˆÙ† Ø­ÙØ¸ Ø§Ù„Ø±Ø§Ø¨Ø·
            return jsonify({
                "status": "skipped_size", 
                "message": f"Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ ({file_size/1024:.2f} KB < 50 KB). ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ Ø¯ÙˆÙ† Ø­ÙØ¸ Ø§Ù„Ø±Ø§Ø¨Ø·."
            }), 200
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 2: Ø¥Ø°Ø§ Ù„Ù… Ù†Ø³ØªØ·Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ø¨Ø± HEADØŒ Ù†Ø­Ù…Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        image_bytes = None
        if is_size_valid is None:
            print(f"[ ğŸ”„ ] HEAD request Ù„Ù… ÙŠÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©. Ø³ÙŠØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©...")
            is_size_valid, image_bytes, file_size = download_to_memory_and_check(image_url, headers)
            
            if not is_size_valid:
                # Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ - ØªÙ… Ø±ÙØ¶Ù‡ Ø¯ÙˆÙ† Ø­ÙØ¸ Ø§Ù„Ø±Ø§Ø¨Ø·
                return jsonify({
                    "status": "skipped_size", 
                    "message": f"Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ ({file_size/1024:.2f} KB < 50 KB). ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ Ø¯ÙˆÙ† Ø­ÙØ¸ Ø§Ù„Ø±Ø§Ø¨Ø·."
                }), 200

        # --- Ø§Ù„Ø¢Ù† Ù†Ø­Ù† ÙˆØ§Ø«Ù‚ÙˆÙ† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…Ù‚Ø¨ÙˆÙ„: Ø§Ø­ÙØ¸Ù‡ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ ---
        timestamp_suffix = str(int(time.time() * 1000))[-6:]
        final_filename = f"{base_filename}_{timestamp_suffix}{extension}"
        filepath = os.path.join(DOWNLOAD_FOLDER, final_filename)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£Ø®ÙŠØ± Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        if os.path.exists(filepath):
            print(f"[ ğŸŸ¡ ] Ø§Ù„Ù…Ù„Ù '{final_filename}' Ù…ÙˆØ¬ÙˆØ¯. ØªÙ… Ø§Ù„ØªØ¬Ø§Ù‡Ù„.")
            add_link_to_db(image_url)
            return jsonify({"status": "skipped", "message": f"Ø§Ù„Ù…Ù„Ù '{final_filename}' Ù…ÙˆØ¬ÙˆØ¯."}), 200

        print(f"[ ğŸ’¾ ] Ø¬Ø§Ø±Ù Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ: {filepath}")
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ Ø§Ø­ÙØ¸Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
        if image_bytes:
            with open(filepath, 'wb') as f:
                f.write(image_bytes)
            print(f"[ âœ… ] ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {final_filename}")
        else:
            # Ø¥Ø°Ø§ ØªØ­Ù‚Ù‚Ù†Ø§ Ø¹Ø¨Ø± HEADØŒ Ø­Ù…Ù‘Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¢Ù†
            print(f"[ â³ ] Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©...")
            response = requests.get(image_url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            print(f"[ âœ… ] ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {final_filename}")
        
        add_link_to_db(image_url)
        
        return jsonify({"status": "success", "message": "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­.", "filename": final_filename}), 201

    except Exception as e:
        print(f"ğŸ’¥ğŸ’¥ğŸ’¥ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø®Ø§Ø¯Ù…! ğŸ’¥ğŸ’¥ğŸ’¥")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…: {str(e)}"}), 500


# --- 4. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… ---
if __name__ == '__main__':
    setup()
    app.run(host='0.0.0.0', port=5003, debug=False)
